{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a spark session with mssql, delta, and hive support enabled\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"sql-server-cdc-with-pyspark\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.microsoft.sqlserver:mssql-jdbc:9.4.1.jre8,io.delta:delta-core_2.12:1.1.0\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "# secrets included for readability; normally they would be in KeyVault, etc.\n",
    "SRC_USER = \"XXXXXX\"\n",
    "SRC_PWD  = \"XXXXXX\"\n",
    "SRC_HOST = \"XXXXXX\"\n",
    "SRC_DB   = \"XXXXXX\"\n",
    "\n",
    "src_table     = \"customers\"\n",
    "src_table_key = \"customer_id\"\n",
    "\n",
    "delta_table_path = f\"/tmp/{src_table}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data and schema of the src table from sql server\n",
    "# NOTE: be sure your IP is allowed in the db firewall\n",
    "df = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", f\"jdbc:sqlserver://{SRC_HOST}:{SRC_PORT}; database={SRC_DB}; fetchsize=20000\") \\\n",
    "        .option(\"dbtable\", f\"dbo.{src_table}\") \\\n",
    "        .option(\"user\", SRC_USER) \\\n",
    "        .option(\"password\", SRC_PWD) \\\n",
    "        .option(\"encrypt\", \"true\") \\\n",
    "        .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "        .option(\"hostNameInCertificate\", \"*.database.windows.net\") \\\n",
    "        .load()\n",
    "\n",
    "# persist it in delta format\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path)\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "  DROP TABLE IF EXISTS {src_table}\n",
    "\"\"\")\n",
    "\n",
    "# create a hive table using the data at the delta location\n",
    "spark.sql(f\"\"\"\n",
    "  CREATE TABLE {src_table}\n",
    "  USING DELTA\n",
    "  LOCATION '{delta_table_path}'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select * from customers\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
